{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c51813-43d7-40cb-a08b-5aac8dd10dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/scratch/junhong/miniconda3/envs/vllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-16 00:21:58,149 | \u001b[92mINFO\u001b[0m | Task-4 | model:<module>:22 - \u001b[92mUsing Qwen/Qwen2.5-Math-PRM-7B for LLM response.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from dataset.math_dataset import MathDatasetLoader\n",
    "from utils import *\n",
    "from utils.logger import *\n",
    "from utils.utils import *\n",
    "from utils.math import *\n",
    "from utils.model import *\n",
    "from utils.qwen_math_parser import *\n",
    "\n",
    "logger = DefaultProgressLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8b11f3-d29e-40f6-a6b1-61e8a95bb575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|█████████████████████████████████████████████| 5383/5383 [00:00<00:00, 14469.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"UWNSL/MATH_training_split_long_cot\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f55fd2-a8c6-41ef-9733-195b36632bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['problem', 'solution'],\n",
       "    num_rows: 5383\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8368bdb-419e-4726-b320-61b027aee65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt='''Given a chain-of-thought reasoning process, your task is to identify and categorize each reasoning step into one of the following categories:\n",
    "\n",
    "1. continue reasoning: encourages the model to build upon its current reasoning trajectory by generating the next intermediate step.\n",
    "2. reflect: prompts the model to pause and verify the correctness of current reasoning path or calculation results. Marked by some keywords like \"wait\" and \"verify\".\n",
    "3. explore: signals the model to explore a alternative and new solution. Marked by some keywords like \"alternative\" and \"another approach\".\n",
    "\n",
    "Here is an example to follow:\n",
    "\n",
    "## Instruction: Let $\\mathcal{C}$ be the hyperbola $y^2 - x^2 = 1$. Given a point $P_0$ on the $x$-axis, we construct a sequence of points $(P_n)$ on the $x$-axis in the following manner: let $\\ell_n$ be the line with slope $n$ passing through $P_n$, then $P_{n+1}$ is the orthogonal projection of the point of intersection of $\\ell_n$ and $\\mathcal C$ onto the $x$-axis. (If $P_n = 0$, then the sequence simply terminates.) Find the sum of the $x$-coordinates of all points $P_n$ if $P_0 = (1,0)$. Your answer should use only integers and $\\ln$..\n",
    "\n",
    "## Response: Given the hyperbola \\(\\mathcal{C}\\) defined by the equation \\(y^2 - x^2 = 1\\), we start with the point \\(P_0 = (1,0)\\). The line \\(\\ell_0\\) passing through \\(P_0\\) with slope \\(0\\) is the horizontal line \\(y = 0\\). The intersection of \\(\\ell_0\\) with \\(\\mathcal{C}\\) is the point \\((1,0)\\) and \\((-1,0)\\). The orthogonal projection of \\((-1,0)\\) onto the \\(x\\)-axis is \\((-1,0)\\), so \\(P_1 = (-1,0)\\).\\n\\nBut wait. The intersection of \\(\\ell_0\\) with \\(\\mathcal{C}\\) is not \\((1,0)\\) and \\((-1,0)\\); it is only \\((0,1)\\) and \\((0,-1)\\).\\n\\nAs an alternative, The correct intersection point to consider is \\((0,1)\\), and the orthogonal projection of \\((0,1)\\) onto the \\(x\\)-axis is \\((0,0)\\), so \\(P_1 = (0,0)\\).\\n\\nLet's re-evaluate the problem correctly. Given the hyperbola \\(\\mathcal{C}\\) defined by the equation \\(y^2 - x^2 = 1\\), we start with the point \\(P_0 = (1,0)\\). The line \\(\\ell_0\\) passing through \\(P_0\\) with slope \\(n\\) is given by \\(y = n(x-1)\\). We need to find the intersection of \\(\\ell_0\\) with \\(\\mathcal{C}\\).\\n\\nSubstitute \\(y = n(x-1)\\) into the hyperbola equation: \\[ (n(x-1))^2 - x^2 = 1 \\] \\[ n^2(x^2 - 2x + 1) - x^2 = 1 \\] \\[ n^2x^2 - 2n^2x + n^2 - x^2 = 1 \\] \\[ (n^2 - 1)x^2 - 2n^2x + n^2 - 1 = 0 \\] This is a quadratic equation in \\(x\\).\\n\\nUsing the quadratic formula \\(x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\), where \\(a = n^2 - 1\\), \\(b = -2n^2\\), and \\(c = n^2 - 1\\), we get: \\[ x = \\frac{2n^2 \\pm \\sqrt{(2n^2)^2 - 4(n^2 - 1)(n^2 - 1)}}{2(n^2 - 1)} \\] \\[ x = \\frac{2n^2 \\pm \\sqrt{4n^4 - 4(n^4 - 2n^2 + 1)}}{2(n^2 - 1)} \\] \\[ x = \\frac{2n^2 \\pm \\sqrt{4n^4 - 4n^4 + 8n^2 - 4}}{2(n^2 - 1)} \\] \\[ x = \\frac{2n^2 \\pm \\sqrt{8n^2 - 4}}{2(n^2 - 1)} \\] \\[ x = \\frac{2n^2 \\pm 2\\sqrt{2n^2 - 1}}{2(n^2 - 1)} \\] \\[ x = \\frac{n^2 \\pm \\sqrt{2n^2 - 1}}{n^2 - 1} \\] The two solutions are \\(x = \\frac{n^2 + \\sqrt{2n^2 - 1}}{n^2 - 1}\\) and \\(x = \\frac{n^2 - \\sqrt{2n^2 - 1}}{n^2 - 1}\\). Since \\(P_0 = (1,0)\\) is on the right side of the hyperbola, we take the negative root to ensure the sequence converges to zero.\\n\\nThus, the \\(x\\)-coordinate of \\(P_{n+1}\\) is: \\[ x_{n+1} = \\frac{n^2 - \\sqrt{2n^2 - 1}}{n^2 - 1} \\] We can simplify this expression further: \\[ x_{n+1} = 1 - \\frac{\\sqrt{2n^2 - 1}}{n^2 - 1} \\] To find the sum of the \\(x\\)-coordinates of all points \\(P_n\\), we need to sum the series: \\[ \\sum_{n=0}^{\\infty} x_n \\] By examining the pattern, we see that each term \\(x_n\\) approaches 0 as \\(n\\) increases. The sum of the series can be found using properties of logarithms and hyperbolic functions. The result is: \\[ \\sum_{n=0}^{\\infty} x_n = \\boxed{1} \\]\n",
    "\n",
    "## Output: \n",
    "{{\n",
    "    \"Given the hyperbola ...\": \"continue reasoning\",\n",
    "    \"But wait. The intersection of...\": \"reflect-effective\",\n",
    "    \"As an alternative, The correct intersection...\": \"explore-0\",\n",
    "    \"Let's re-evaluate the problem correctly...\": \"reflect-ineffective\",\n",
    "    \"Substitute \\(y = n(x-1)\\) into...\": \"continue reasoning\",\n",
    "    \"Using the quadratic formula...\": \"continue reasoning\",\n",
    "    \"Thus, the \\(x\\)-coordinate of...\": \"continue reasoning\"\n",
    "}}\n",
    "\n",
    "Noted that each reasoning step is seperated by \\n\\n. As the demonstration shows, each single reasoning step's brief content and its reasoning category should be a key-value pair in the dictionary. For the explore step, the number followed by \"explore\" means which step it goes back to and explores from. For example, explore-0 means the reasoning process goes back to the very beginning and tries to find an alternative solution. Only reflecting steps that lead to a different answer should be reflect-effective, otherwise, it should be reflect-ineffective.\n",
    "Formatted the example above and think step by step to categorize reasoning step for the following case:'''\n",
    "\n",
    "user_message = \"\"\"\n",
    "##Instruction: {problem}\n",
    "\n",
    "##Response: {response}\n",
    "\n",
    "##Output:\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = user_message.format(\n",
    "    problem=problem, \n",
    "    response=response\n",
    ")\n",
    "generate_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee3be1-a560-4eaa-9385-de6a6261a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "from enum import Enum\n",
    "\n",
    "class AggregationMethod(Enum):\n",
    "    MODEL = \"model\"\n",
    "    PRODUCT = \"prod\"\n",
    "    MIN = \"min\"\n",
    "    LAST = \"last\"\n",
    "\n",
    "class AbstractProcessRewardModel(ABC):\n",
    "    \"\"\"abstract base class for process reward models\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def score(self, question: str, responses: List[str], step_sep: str = \"\\n\\n\", aggregation_method: str = None, return_full_prm_result: bool = False, max_input_tokens: int = 8196) -> Union[List[PRMResult], List[float]]:\n",
    "        \"\"\"the reward for the given steps\"\"\"\n",
    "        pass\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Union, List\n",
    "import os\n",
    "from vllm import LLM\n",
    "\n",
    "class VllmProcessRewardModel(AbstractProcessRewardModel):\n",
    "    def __init__(self, model_name: str, device: Union[str, int], **kwargs):\n",
    "        os.environ[\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\"] = \"1\"\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs: {num_gpus}\")\n",
    "        \n",
    "        self.model = LLM(model=model_name, \n",
    "                    task=\"reward\",\n",
    "                    device=device,\n",
    "                    gpu_memory_utilization=0.8,\n",
    "                    tensor_parallel_size=1,\n",
    "                    )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        if model_name == \"Qwen/Qwen2.5-Math-PRM-7B\":\n",
    "            self.tokenizer.truncation_side = \"left\"\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def score(self, messages: Union[List[List[dict]], List[dict]], max_input_tokens: int = 8192, step_sep: str = \"\\n\\n\",\n",
    "             aggregation_method: Union[AggregationMethod, str] = AggregationMethod.LAST, return_full_prm_result: bool = False, use_tqdm: bool = False) -> Union[List[PRMResult], List[float]]:\n",
    "        \"\"\"\n",
    "        Score last turn assistant message using the OpenAI chat completion format.\n",
    "        \n",
    "        Args:\n",
    "            messages: List of conversations in OpenAI chat completion format\n",
    "            max_input_tokens: Maximum number of input tokens\n",
    "            return_full_prm_result: Whether to return full PRM results\n",
    "            use_tqdm: Whether to display a progress bar (using tqdm)\n",
    "        \"\"\"\n",
    "        if isinstance(aggregation_method, str):\n",
    "            aggregation_method = AggregationMethod(aggregation_method)\n",
    "        if isinstance(messages[0], dict):\n",
    "            # ensure the input is a list of list of dicts   \n",
    "            messages = [messages]\n",
    "        if self.model_name == \"Qwen/Qwen2.5-Math-PRM-7B\":\n",
    "            formatted_convs = []\n",
    "            QWEN_PRM_SYSTEM_PROMPT = \"Please reason step by step, and put your final answer within \\\\boxed{}.\"\n",
    "            system_turn = [{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": QWEN_PRM_SYSTEM_PROMPT\n",
    "            }]\n",
    "            for conv_messages in messages:\n",
    "\n",
    "                last_assistant_message = conv_messages[-1]['content']\n",
    "                if aggregation_method == AggregationMethod.MODEL:\n",
    "                    steps_list = [last_assistant_message]\n",
    "                else:\n",
    "                    steps_list = last_assistant_message.split(step_sep)\n",
    "                formatted_last_assistant_turn = [\n",
    "                    {\"role\": \"assistant\", \"content\": \"<extra_0>\".join(steps_list) + \"<extra_0>\"}\n",
    "                ]\n",
    "                prepared_messages = system_turn + conv_messages[:-1] + formatted_last_assistant_turn\n",
    "                conversation = self.tokenizer.apply_chat_template(\n",
    "                    prepared_messages,\n",
    "                    tokenize=False, \n",
    "                    add_generation_prompt=False\n",
    "                )\n",
    "                formatted_convs.append(conversation)\n",
    "\n",
    "            all_input_ids = self.tokenizer(\n",
    "                formatted_convs,\n",
    "                return_tensors=\"pt\", \n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=max_input_tokens\n",
    "            ).input_ids\n",
    "            batch_decoded = self.tokenizer.batch_decode(all_input_ids, skip_special_tokens=False)\n",
    "            all_outputs = self.model.encode(batch_decoded, use_tqdm=use_tqdm)\n",
    "            all_scores = [[d[-1].item() for d in ex.outputs.data] for ex in all_outputs]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Model {self.model_name} is not supported\")\n",
    "        \n",
    "        if return_full_prm_result:\n",
    "            return [PRMResult(scores=scores) for scores in all_scores]\n",
    "        else:\n",
    "            return [PRMResult(scores=scores, aggregation_method=aggregation_method).score for scores in all_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66813969-61dd-487f-831d-6b8026b7b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1349155/3145129444.py:9: RuntimeWarning: coroutine 'complete_response' was never awaited\n",
      "  response = await complete_response(user_message, max_tokens=256, return_raw=True)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2025-06-16 00:25:01,081 | \u001b[92mINFO\u001b[0m | Task-10 | 3145129444:<module>:10 - \u001b[92mCompletion(id=None, choices=None, created=None, model=None, object='error', system_fingerprint=None, usage=None, message='The model does not support Completions API', type='BadRequestError', param=None, code=400)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\\\n",
    "Hello! What is 1+2+3+...+100=?\n",
    "\"\"\"\n",
    "\n",
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": user_message},\n",
    "]\n",
    "# response = await generate_response(prompt, max_tokens=256, return_raw=True)\n",
    "response = await complete_response(user_message, max_tokens=256, return_raw=True)\n",
    "logger.info(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8e328-5a38-4073-a351-3780b735834b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
